"""
BSC Quest Controller - æ§åˆ¶å±‚

è´Ÿè´£:
1. ç®¡ç† LLM è¾“å…¥è¾“å‡º
2. åè°ƒå„å±‚äº¤äº’ (ç¯å¢ƒå±‚ã€æ‰§è¡Œå±‚ã€éªŒè¯å™¨)
3. æå– TypeScript ä»£ç å—
4. ä¿å­˜è¯„åˆ†æŒ‡æ ‡
"""

import json
import re
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List

from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

from .quest_env import QuestEnvironment
from .quest_executor import QuestExecutor
from .parameter_generator import ParameterGenerator, format_parameter_value


class QuestController:
    """Quest æ§åˆ¶å™¨ - åè°ƒå•è½®äº¤æ˜“ç”Ÿæˆè¯„ä¼°"""
    
    def __init__(
        self,
        model_name: str,
        question_path: str,
        validator_class,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        fork_url: str = "https://bsc-testnet.drpc.org",
        test_mode: bool = False,
        test_code_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–æ§åˆ¶å™¨
        
        Args:
            model_name: LLM æ¨¡å‹åç§° (ä¾‹å¦‚: "anthropic/claude-sonnet-4", "gpt-4")
            question_path: é—®é¢˜é…ç½®æ–‡ä»¶è·¯å¾„
            validator_class: éªŒè¯å™¨ç±»
            api_key: API key (å¦‚æœä¸º None åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡)
            base_url: è‡ªå®šä¹‰ API base URL (å¯é€‰)
            fork_url: BSC RPC URL (é»˜è®¤: testnet)
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨é¢„å…ˆç¼–å†™çš„ä»£ç è€Œä¸æ˜¯è°ƒç”¨ LLM
            test_code_path: æµ‹è¯•ä»£ç è·¯å¾„ï¼ˆä»…æµ‹è¯•æ¨¡å¼æœ‰æ•ˆï¼‰
        """
        self.model_name = model_name
        self.question_path = question_path
        self.validator_class = validator_class
        self.api_key = api_key
        self.base_url = base_url
        self.fork_url = fork_url
        self.test_mode = test_mode
        self.test_code_path = test_code_path
        
        # åŠ è½½ç³»ç»Ÿé…ç½®
        self.system_config = self._load_system_config()
        
        # åŠ è½½é—®é¢˜é…ç½®
        self.question = self._load_question()
        
        # åˆå§‹åŒ–å‚æ•°ç”Ÿæˆå™¨
        self.param_generator = ParameterGenerator()
        
        # ç”Ÿæˆéšæœºå‚æ•°å€¼
        self.generated_params = self._generate_parameters()
        
        # åˆå§‹åŒ– LLM
        self.llm = self._init_llm(model_name, api_key, base_url)
        
        # å­˜å‚¨ç»“æœ
        self.result = {
            'question_id': self.question['id'],
            'model_name': model_name,
            'start_time': None,
            'end_time': None,
            'generated_params': self.generated_params,
            'natural_language_prompt': None,
            'llm_response': None,
            'extracted_code': None,
            'execution_success': False,
            'validation_result': None,
            'error': None
        }
    
    def _load_system_config(self) -> Dict[str, Any]:
        """Load system configuration (role and environment prompts)"""
        config_file = Path(__file__).parent / 'system_config.json'
        if not config_file.exists():
            raise FileNotFoundError(f"System configuration file not found: {config_file}")
        
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_question(self) -> Dict[str, Any]:
        """Load question configuration"""
        question_file = Path(self.question_path)
        if not question_file.exists():
            raise FileNotFoundError(f"Question configuration file not found: {self.question_path}")
        
        with open(question_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _generate_parameters(self) -> Dict[str, Any]:
        """Generate random parameter values based on question configuration"""
        if not self.question.get('parameters'):
            return {}
        
        return self.param_generator.generate_parameters(self.question['parameters'])
    
    def _regenerate_env_parameters(self, env):
        """
        é‡æ–°ç”Ÿæˆéœ€è¦ç¯å¢ƒçš„å‚æ•°ï¼ˆmethod='from_env'ï¼‰
        
        Args:
            env: QuestEnvironmentå®ä¾‹
        """
        params_config = self.question.get('parameters', {})
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦ä»ç¯å¢ƒè·å–çš„å‚æ•°
        has_env_params = False
        env_param_names = []
        for param_name, param_config in params_config.items():
            generation_config = param_config.get('generation', {})
            if generation_config.get('method') == 'from_env':
                has_env_params = True
                env_param_names.append(param_name)
        
        if not has_env_params:
            return
        
        print(f"ğŸ”„ é‡æ–°ç”Ÿæˆç¯å¢ƒå‚æ•°: {', '.join(env_param_names)}")
        
        # é‡æ–°åˆ›å»ºå¸¦ç¯å¢ƒçš„å‚æ•°ç”Ÿæˆå™¨
        env_param_generator = ParameterGenerator(environment=env)
        
        # é‡æ–°ç”Ÿæˆæ‰€æœ‰å‚æ•°
        new_params = env_param_generator.generate_parameters(params_config)
        
        # æ˜¾ç¤ºæ›´æ–°çš„å‚æ•°
        for param_name in env_param_names:
            old_value = self.generated_params.get(param_name, 'N/A')
            new_value = new_params.get(param_name, 'N/A')
            print(f"  â€¢ {param_name}: {old_value[:10]}... â†’ {new_value}")
        
        # æ›´æ–°å‚æ•°
        self.generated_params.update(new_params)
        
        # é‡æ–°ç”Ÿæˆè‡ªç„¶è¯­è¨€æç¤º
        self.result['natural_language_prompt'] = self._generate_natural_language_prompt()
        print()
    
    def _init_llm(
        self,
        model_name: str,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        
        Args:
            model_name: æ¨¡å‹åç§°
            api_key: API key
            base_url: è‡ªå®šä¹‰ API base URL
            
        Returns:
            LLM å®¢æˆ·ç«¯å®ä¾‹
        """
        if not model_name:
            raise ValueError("æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
        
        llm_kwargs = {'model': model_name, 'temperature': 0.7}
        
        # ä¼˜å…ˆçº§ 1: è‡ªå®šä¹‰ base_url
        if base_url:
            print(f"ğŸ”„ ä½¿ç”¨è‡ªå®šä¹‰ API: {base_url}")
            print(f"   æ¨¡å‹: {model_name}")
            if api_key:
                llm_kwargs['api_key'] = api_key
            llm_kwargs['base_url'] = base_url
            return ChatOpenAI(**llm_kwargs)
        
        # ä¼˜å…ˆçº§ 2: OpenRouter (æ¨¡å‹ååŒ…å« '/')
        if '/' in model_name:
            print(f"ğŸ”„ ä½¿ç”¨ OpenRouter")
            print(f"   æ¨¡å‹: {model_name}")
            if api_key:
                llm_kwargs['api_key'] = api_key
                if not api_key.startswith('sk-or-v1-'):
                    print(f"âš ï¸  è­¦å‘Š: OpenRouter API key é€šå¸¸ä»¥ 'sk-or-v1-' å¼€å¤´")
                    print(f"   æ‚¨çš„ key å¼€å¤´: {api_key[:10]}...")
            else:
                print(f"âš ï¸  è­¦å‘Š: æœªæä¾› OpenRouter API key")
            
            llm_kwargs['base_url'] = "https://openrouter.ai/api/v1"
            llm_kwargs['default_headers'] = {
                "HTTP-Referer": "https://github.com/bsc-quest-bench",
                "X-Title": "BSC Quest Bench"
            }
            return ChatOpenAI(**llm_kwargs)
        
        # ä¼˜å…ˆçº§ 3: æ ‡å‡† provider
        if 'gpt' in model_name.lower() or 'openai' in model_name.lower():
            if api_key:
                llm_kwargs['openai_api_key'] = api_key
            return ChatOpenAI(**llm_kwargs)
        elif 'claude' in model_name.lower() or 'anthropic' in model_name.lower():
            if api_key:
                llm_kwargs['anthropic_api_key'] = api_key
            return ChatAnthropic(**llm_kwargs)
        elif 'gemini' in model_name.lower() or 'google' in model_name.lower():
            if api_key:
                llm_kwargs['google_api_key'] = api_key
            return ChatGoogleGenerativeAI(**llm_kwargs)
        else:
            if api_key:
                llm_kwargs['openai_api_key'] = api_key
            return ChatOpenAI(**llm_kwargs)
    
    def _generate_natural_language_prompt(self) -> str:
        """Generate natural language prompt with filled parameters"""
        templates = self.question.get('natural_language_templates', [])
        if not templates:
            raise ValueError("No natural language templates defined for this question")
        
        # Choose a random template
        import random
        template = random.choice(templates)
        
        # Fill in the parameters
        for param_name, param_value in self.generated_params.items():
            param_config = self.question['parameters'][param_name]
            formatted_value = format_parameter_value(param_value, param_config)
            template = template.replace(f"{{{param_name}}}", formatted_value)
        
        return template
    
    def _generate_system_prompt(self) -> str:
        """
        Generate system prompt with four parts:
        1. Role prompt (same for all questions)
        2. Environment description (same for all questions)
        3. Question-specific context (optional, from question description)
        4. Natural language prompt (unique per question, with random values)
        """
        # Part 1: Role prompt (æ”¯æŒæ•°ç»„æˆ–å­—ç¬¦ä¸²æ ¼å¼)
        role_prompt_raw = self.system_config['role_prompt']
        role_prompt = '\n'.join(role_prompt_raw) if isinstance(role_prompt_raw, list) else role_prompt_raw
        
        # Part 2: Environment description (æ”¯æŒæ•°ç»„æˆ–å­—ç¬¦ä¸²æ ¼å¼)
        env_description_raw = self.system_config['environment_description']
        env_description = '\n'.join(env_description_raw) if isinstance(env_description_raw, list) else env_description_raw
        
        # Part 3: Question-specific context (optional, from description field)
        question_context = ""
        if 'description' in self.question:
            description_raw = self.question['description']
            description = '\n'.join(description_raw) if isinstance(description_raw, list) else description_raw
            question_context = f"\n\nContext for this task:\n{description}"
        
        # Part 4: Natural language prompt with random values
        natural_language_prompt = self._generate_natural_language_prompt()
        
        # Store the natural language prompt for logging
        self.result['natural_language_prompt'] = natural_language_prompt
        
        # Combine all parts
        full_prompt = f"{role_prompt}\n\n{env_description}{question_context}\n\nTask:\n{natural_language_prompt}"
        
        return full_prompt
    
    def extract_code_blocks(self, text: str) -> List[str]:
        """
        æå–ä»£ç å—
        
        Args:
            text: LLM å“åº”æ–‡æœ¬
            
        Returns:
            ä»£ç å—åˆ—è¡¨
        """
        pattern = r'```(?:typescript|ts|javascript|js)?\s*\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        return [match.strip() for match in matches if match.strip()]
    
    def _load_test_code(self) -> str:
        """
        åŠ è½½æµ‹è¯•ä»£ç å¹¶æ›¿æ¢å‚æ•°å ä½ç¬¦
        
        Returns:
            æ›¿æ¢å‚æ•°åçš„ä»£ç 
        """
        if not self.test_code_path:
            raise ValueError("Test mode enabled but no test_code_path provided")
        
        # è¯»å–æµ‹è¯•ä»£ç 
        with open(self.test_code_path, 'r', encoding='utf-8') as f:
            code = f.read()
        
        # æ›¿æ¢å‚æ•°å ä½ç¬¦
        for param_name, param_value in self.generated_params.items():
            placeholder = f"{{{{{param_name}}}}}"  # {{param_name}}
            code = code.replace(placeholder, str(param_value))
        
        return code
    
    def _save_code_to_temp_file(self, code: str) -> str:
        """
        ä¿å­˜ä»£ç åˆ°ä¸´æ—¶æ–‡ä»¶
        
        Args:
            code: TypeScript ä»£ç 
            
        Returns:
            ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨ skill_runner/temp/ ç›®å½•è€Œä¸æ˜¯ç³»ç»Ÿ /tmp/
        # è¿™æ · Bun èƒ½æ­£ç¡®è§£æ node_modules
        timestamp = int(time.time() * 1000)
        project_root = Path(__file__).parent.parent
        temp_dir = project_root / 'bsc_gym_env' / 'skill_runner' / 'temp'
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        code_file = temp_dir / f'temp_skill_{timestamp}.ts'
        
        with open(code_file, 'w', encoding='utf-8') as f:
            f.write(code)
        
        return str(code_file)
    
    async def run(self) -> Dict[str, Any]:
        """
        è¿è¡Œå•è½®è¯„ä¼°
        
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("="*80)
        print("BSC Quest Bench - å•è½®è¯„ä¼°")
        print("="*80)
        print(f"é—®é¢˜ID: {self.question['id']}")
        print(f"æ¨¡å‹: {self.model_name}")
        print(f"éš¾åº¦: {self.question['difficulty']}")
        print("="*80)
        print()
        
        self.result['start_time'] = datetime.now().isoformat()
        
        # 1. å¯åŠ¨ç¯å¢ƒ
        print("ğŸ”§ å¯åŠ¨ç¯å¢ƒ...")
        env = QuestEnvironment(fork_url=self.fork_url)
        env_info = env.start()
        print()
        
        # 1.5 é‡æ–°ç”Ÿæˆéœ€è¦ç¯å¢ƒçš„å‚æ•°ï¼ˆå¦‚ from_envï¼‰
        self._regenerate_env_parameters(env)
        
        try:
            # 2. æ˜¾ç¤ºç”Ÿæˆçš„å‚æ•°
            print("ğŸ“ Generated Natural Language Prompt:")
            if not self.test_mode:
                system_prompt = self._generate_system_prompt()
                print(f"   \"{self.result['natural_language_prompt']}\"")
            else:
                print(f"   [TEST MODE - Skipped]")
            
            print(f"\nğŸ“Š Generated Parameters:")
            for param_name, param_value in self.generated_params.items():
                print(f"   - {param_name}: {param_value}")
            print()
            
            # 3. è·å–ä»£ç ï¼šæµ‹è¯•æ¨¡å¼æˆ– LLM ç”Ÿæˆ
            if self.test_mode:
                # æµ‹è¯•æ¨¡å¼ï¼šä»æ–‡ä»¶åŠ è½½ä»£ç 
                print("ğŸ§ª TEST MODE: Loading code from test file...")
                code = self._load_test_code()
                self.result['llm_response'] = "[TEST MODE] Code loaded from file"
                self.result['extracted_code'] = code
                print(f"âœ… Test code loaded from: {self.test_code_path}")
                print()
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šè°ƒç”¨ LLM
                print("ğŸ¤– Calling LLM to generate code...")
                messages = [
                    SystemMessage(content=system_prompt)
                ]
                
                response = await self.llm.ainvoke(messages)
                self.result['llm_response'] = response.content
                
                print(f"âœ… LLM response received ({len(response.content)} characters)")
                print()
                
                # 4. æå–ä»£ç å—
                print("ğŸ“ æå–ä»£ç å—...")
                code_blocks = self.extract_code_blocks(response.content)
                
                if not code_blocks:
                    error_msg = "æœªæ‰¾åˆ° TypeScript ä»£ç å—"
                    print(f"âŒ {error_msg}")
                    self.result['error'] = error_msg
                    return self.result
                
                code = code_blocks[0]
                self.result['extracted_code'] = code
                print(f"âœ… æå–åˆ° {len(code_blocks)} ä¸ªä»£ç å—")
                print()
            
            print("â”€"*80)
            print("æå–çš„ä»£ç :")
            print("â”€"*80)
            print(code)
            print("â”€"*80)
            print()
            
            # 5. æ‰§è¡Œä»£ç ç”Ÿæˆäº¤æ˜“å¯¹è±¡
            print("âš™ï¸  æ‰§è¡Œ TypeScript ä»£ç ...")
            from .skill_manager.ts_skill_manager import TypeScriptSkillManager
            
            skill_manager = TypeScriptSkillManager(use_bun=True)
            code_file = self._save_code_to_temp_file(code)
            
            try:
                tx_result = skill_manager.execute_skill(
                    code_file=code_file,
                    provider_url=env_info['rpc_url'],
                    agent_address=env_info['test_address'],
                    deployed_contracts={}
                )
                
                if not tx_result.get('success'):
                    error_msg = tx_result.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"âŒ TypeScript æ‰§è¡Œå¤±è´¥: {error_msg}")
                    self.result['error'] = error_msg
                    return self.result
                
                tx = tx_result['tx_object']
                print(f"âœ… äº¤æ˜“å¯¹è±¡ç”ŸæˆæˆåŠŸ")
                print(f"   To: {tx.get('to')}")
                print(f"   Value: {tx.get('value')}")
                print()
                
            finally:
                import os
                if os.path.exists(code_file):
                    os.unlink(code_file)
            
            # 6. åˆ›å»ºæ‰§è¡Œå™¨å¹¶æ‰§è¡Œäº¤æ˜“
            print("ğŸ”— æ‰§è¡Œäº¤æ˜“...")
            executor = QuestExecutor(
                w3=env.w3,
                private_key=env_info['test_private_key']
            )
            
            # åˆ›å»ºéªŒè¯å™¨
            validator = self._create_validator(self.generated_params)
            
            # å‡†å¤‡ token ç›¸å…³å‚æ•°ï¼ˆå¦‚æœæ˜¯ ERC20 æ“ä½œæˆ– WBNB æ“ä½œï¼‰
            token_address = None
            target_address_for_token = None
            spender_address = None
            nft_address = None
            nft_token_id = None
            operator_address = None
            nft_type = None
            counter_contract_address = None
            message_board_contract_address = None
            proxy_address = None
            implementation_address = None
            expected_value = None
            
            if self.question.get('subcategory') == 'erc20_operations':
                token_address = self.generated_params.get('token_address')
                target_address_for_token = self.generated_params.get('to_address')
                spender_address = self.generated_params.get('spender_address')
            elif self.question.get('id') in ['wbnb_deposit', 'wbnb_withdraw']:
                # WBNB deposit/withdraw éœ€è¦æŸ¥è¯¢ WBNB token ä½™é¢
                token_address = self.generated_params.get('wbnb_address')
            elif self.question.get('subcategory') == 'flashloan':
                # é—ªç”µè´·éœ€è¦æŸ¥è¯¢ token ä½™é¢ï¼ˆç”¨äºéªŒè¯è´¹ç”¨æ”¯ä»˜ï¼‰
                token_address = self.generated_params.get('token_address')
            elif self.question.get('id') == 'contract_call_simple':
                # SimpleCounter åˆçº¦éœ€è¦æŸ¥è¯¢ counter å€¼
                counter_contract_address = self.generated_params.get('contract_address')
            elif self.question.get('id') == 'contract_call_with_params':
                # MessageBoard åˆçº¦éœ€è¦æŸ¥è¯¢ message å€¼
                message_board_contract_address = self.generated_params.get('contract_address')
            elif self.question.get('subcategory') == 'delegate_call':
                # DelegateCall éœ€è¦æŸ¥è¯¢ proxy å’Œ implementation çš„å€¼
                proxy_address = self.generated_params.get('proxy_address')
                implementation_address = self.generated_params.get('implementation_address')
                expected_value = self.generated_params.get('value')
            elif self.question.get('subcategory') == 'nft_operations':
                # NFT æ“ä½œéœ€è¦æŸ¥è¯¢ NFT æ‰€æœ‰æƒ
                nft_address = self.generated_params.get('nft_address')
                nft_token_id = self.generated_params.get('token_id')
                operator_address = self.generated_params.get('operator_address')
                
                # æ ¹æ®é—®é¢˜ ID åˆ¤æ–­ NFT ç±»å‹
                question_id = self.question.get('id', '')
                if 'erc1155' in question_id:
                    nft_type = 'erc1155'
                    # ERC1155 transfer æ“ä½œè¿˜éœ€è¦æŸ¥è¯¢ç›®æ ‡åœ°å€çš„ä½™é¢
                    target_address_for_token = self.generated_params.get('to_address')
                elif 'erc721' in question_id:
                    nft_type = 'erc721'
                else:
                    nft_type = None
            
            # æ‰§è¡Œäº¤æ˜“
            execution_result = executor.execute_transaction(
                tx,
                validator,
                token_address=token_address,
                target_address_for_token=target_address_for_token,
                spender_address=spender_address,
                nft_address=nft_address,
                nft_token_id=nft_token_id,
                operator_address=operator_address,
                nft_type=nft_type,
                counter_contract_address=counter_contract_address,
                message_board_contract_address=message_board_contract_address,
                proxy_address=proxy_address,
                implementation_address=implementation_address,
                expected_value=expected_value
            )
            
            self.result['execution_success'] = execution_result['success']
            
            if execution_result['success']:
                self.result['validation_result'] = execution_result['validation']
                print()
                print("="*80)
                print("ğŸ“Š è¯„ä¼°ç»“æœ")
                print("="*80)
                print(f"âœ… äº¤æ˜“æ‰§è¡ŒæˆåŠŸ")
                print(f"éªŒè¯é€šè¿‡: {'âœ…' if execution_result['validation']['passed'] else 'âŒ'}")
                print(f"å¾—åˆ†: {execution_result['validation']['score']}/{execution_result['validation']['max_score']}")
                print("="*80)
            else:
                error_msg = execution_result.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ äº¤æ˜“æ‰§è¡Œå¤±è´¥: {error_msg}")
                self.result['error'] = error_msg
            
        finally:
            # æ¸…ç†ç¯å¢ƒ
            print("\nğŸ§¹ æ¸…ç†ç¯å¢ƒ...")
            env.stop()
        
        self.result['end_time'] = datetime.now().isoformat()
        return self.result
    
    def _create_validator(self, params: Dict[str, Any]):
        """
        åˆ›å»ºéªŒè¯å™¨å®ä¾‹
        
        Args:
            params: Generated parameters for this test case
            
        Returns:
            éªŒè¯å™¨å®ä¾‹
        """
        # validator_class åº”è¯¥æ˜¯ä¸€ä¸ªå·¥å‚å‡½æ•°
        # å®ƒæ¥å— params å¹¶è¿”å›éªŒè¯å™¨å®ä¾‹
        if callable(self.validator_class):
            return self.validator_class(**params)
        else:
            raise ValueError("validator_class must be callable")
    
    def save_result(self, output_path: str):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.result, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

